{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import re\n",
    "import os\n",
    "import importlib\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter, FuncFormatter\n",
    "\n",
    "import trmc.kin as kin\n",
    "import trmc.load as load\n",
    "import trmc.analysis as analysis\n",
    "import trmc.plot as plot\n",
    "from trmc.plot import exp_formatter\n",
    "\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 8]\n",
    "mpl.rc('font',**{'size' : 16})\n",
    "\n",
    "e0 = 8.854e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r da_dv\n",
    "%store -r da_bv\n",
    "# %store -r da_sw\n",
    "# %store -r da_dcs\n",
    "\n",
    "da_dv = da_dv.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Delta V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = None if (len(da_dv.indexes['sample']) == 1)  else 'sample'\n",
    "row = None if (len(da_dv.indexes['direction']) == 1)  else 'direction'\n",
    "timeslice = slice(0e-9,1000e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate the dark cavity sweep to match with the delta v data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (dist: 6, direction: 1, freq: 109)>\n",
       "array([[[    nan,     nan, ...,     nan,     nan]],\n",
       "\n",
       "       [[    nan,     nan, ...,     nan,     nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.02643, 0.02636, ...,     nan,     nan]],\n",
       "\n",
       "       [[    nan,     nan, ...,     nan,     nan]]])\n",
       "Coordinates:\n",
       "  * freq       (freq) float64 8.41e+09 8.416e+09 ... 8.875e+09 8.882e+09\n",
       "    sample     <U16 'bia_normalholder'\n",
       "  * direction  (direction) object 'U'\n",
       "  * dist       (dist) int64 10 11 12 13 8 9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_bv = da_bv.isel(sample = 0).dropna('dist','all')\n",
    "da_bv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dv = da_dv.isel(sample = 0).dropna('dist','all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dcsi = da_bv.interp_like(da_dv,method = 'nearest')\n",
    "v0s = da_dcsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0s = v0s.expand_dims('sample')\n",
    "da_bv = da_bv.expand_dims('sample')\n",
    "da_dv = da_dv.expand_dims('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now just pull out one freqt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittype = 'lor'\n",
    "# fittype = 'lorline'\n",
    "# fittype = 'poly'\n",
    "\n",
    "if fittype == 'lor':\n",
    "    Rinf = 0.02125\n",
    "    f0 = None\n",
    "    p0_default =[f0,0.01,Rinf,1e7]\n",
    "    p_labels = ['f0','R0','Rinf','w'] \n",
    "    epsilon = 0.001 #problems with fixing R0 when this gets too smalll??? fit does not respond to bounds on R0 properly...\n",
    "    window = 100\n",
    "    samps = v0s.indexes['sample']\n",
    "    Ks = pd.Series(index = samps) #Define only for lorentzian as poly fits need Ks\n",
    "    fixR0 = True\n",
    "\n",
    "if fittype == 'lorline':\n",
    "    Rinf = 0.02125\n",
    "    f0 = None\n",
    "    w = 1e7\n",
    "    p0_default =[f0,0.01,Rinf,w, 0.001/w, 0]\n",
    "    p_labels = ['f0','R0','Rinf','w', 'm','b'] \n",
    "    epsilon = 0.001 #problems with fixing R0 when this gets too smalll??? fit does not respond to bounds on R0 properly...\n",
    "    window = 100\n",
    "    samps = v0s.indexes['sample']\n",
    "    Ks = pd.Series(index = samps) #Define only for lorentzian as poly fits need Ks\n",
    "    fixR0 = True\n",
    "    \n",
    "# TODO: need to pass out all covariance only happening for one lor fn\n",
    "    \n",
    "elif fittype == 'poly':\n",
    "    window = 2\n",
    "    p_labels = [ 'f0','R0', 'p0','p1','p2']\n",
    "    bounds = ([-np.inf,-np.inf,-np.inf],[np.inf,np.inf,np.inf])\n",
    "    p0_default = [.01,1e-9,1e-18]\n",
    "    \n",
    "\n",
    "def defaultbounds(fittype, fixR0, Rinf= Rinf):\n",
    "    boundsdict = {\n",
    "        'fixR0':{\n",
    "            'lor' : ([0,0,Rinf - epsilon,0 ],[np.inf,np.inf,Rinf + epsilon,np.inf ]),\n",
    "            'lorline': ([0,0,Rinf - epsilon,0 ,-np.inf,0],[np.inf,np.inf,Rinf + epsilon,np.inf ,np.inf,np.inf]),\n",
    "            'poly': ([-np.inf,-np.inf,-np.inf],[np.inf,np.inf,np.inf])\n",
    "        },\n",
    "        'varyR0':{\n",
    "            'lor' : ([0,0,0, 0],[np.inf,np.inf,np.inf, np.inf]),\n",
    "            'lorline': ([0,0,0, 0,-np.inf,0-0.001],[np.inf,np.inf,np.inf, np.inf,np.inf,0+0.001]),\n",
    "            'poly': ([-np.inf,-np.inf,-np.inf],[np.inf,np.inf,np.inf])\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    if fixR0:\n",
    "        return boundsdict['fixR0'][fittype]\n",
    "    else:\n",
    "        return boundsdict['varyR0'][fittype]\n",
    "\n",
    "    \n",
    "time1 = 0e-9\n",
    "time2 = 1800e-9\n",
    "timerange = slice(time1,time2)\n",
    "timestep = 10e-9 #not index and has been moved inside for loop...need to check\n",
    "\n",
    "# direcs = v0s.indexes['direction'].values\n",
    "direcs = ['U']\n",
    "\n",
    "samps = v0s.indexes['sample']\n",
    "# samps = ['bia','bid']\n",
    "flus = slice(-1,-2,-1)\n",
    "# seldicts = list(analysis.dict_product({'sample' :samps, 'direction':direcs}))\n",
    "\n",
    "seldicts = list(analysis.dict_product({'sample' :samps, 'direction':direcs, 'dist': v0s.indexes['dist']}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data and perform fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K sample bia_normalholder = 42673.83638945927\n",
      "0.0 %\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "###Setup dictionaries to input paramters into\n",
    "da_p = da_dv.isel(freq = 0).drop('freq').where(False).copy()\n",
    "da_p0 = v0s.isel(freq = 0).drop('freq').where(False).copy()\n",
    "\n",
    "da_p_dict = {}\n",
    "da_p0_dict = {}\n",
    "for p in p_labels:\n",
    "    da_p_dict[p] = da_p\n",
    "    da_p0_dict[p] = da_p0\n",
    "    \n",
    "#Not exactly sure why I have to do this copying. Otherwise I think the reference to the original numpy array is kept and assignments get all weird\n",
    "ds_p = xr.Dataset(da_p_dict).copy(deep=True)\n",
    "ds_p0 = xr.Dataset(da_p0_dict).copy(deep=True)\n",
    "\n",
    "ds_p_r  =  ds_p.sel(time = timerange).copy(deep = True).where(False)   #nessecary, subselection is currently not done for ds_p0\n",
    "ds_cov_r  =  ds_p.sel(time = timerange).copy(deep = True).where(False)   #nessecary, subselection is currently not done for ds_p0\n",
    "\n",
    "\n",
    "###Generate Vshift data array\n",
    "dvs = da_dv.sel(time = timerange)\n",
    "vss = v0s + dvs\n",
    "\n",
    "###Create data arrays to put fits into\n",
    "fits_v0 = v0s.copy(deep= True).where(False)\n",
    "fits = dvs.copy(deep = True).where(False)\n",
    "\n",
    "#numer of fits for percent indicator, not working. \n",
    "num = len(seldicts)*(abs(flus.stop - flus.start))\n",
    "\n",
    "\n",
    "\n",
    "### FITTING\n",
    "\n",
    "for seldict in seldicts:\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    ### V0 fitting\n",
    "    v0 = v0s.sel(seldict).dropna('freq','all')\n",
    "\n",
    "    p0 =p0_default\n",
    "    if fittype == 'lor' or fittype == 'lorline': p0[0] = None       \n",
    "    bounds = defaultbounds(fittype,False)\n",
    "    v0_fit, v0_p,v0_sl = analysis.fitsweep(v0, p0, bounds, window , fittype,p_labels)\n",
    "    popt = v0_p[0]\n",
    "    Rinfv0 = popt[2]\n",
    "    \n",
    "    freqs = v0.indexes['freq'][v0_sl]\n",
    "    seldict_coords = copy.deepcopy(seldict)\n",
    "    seldict_coords['freq'] = freqs\n",
    "    fits_v0.loc[seldict_coords] = v0_fit(freqs)\n",
    "\n",
    "    for j, p in enumerate(ds_p0.data_vars):\n",
    "        ds_p0[p].loc[seldict] = popt[j]\n",
    "    \n",
    "    if fittype == 'lor' or fittype == 'lorline' :\n",
    "        Ks[seldict['sample']] = analysis.calc_K(f0 = popt[0], R0_norm = popt[1]/popt[2],w = popt[3], printparams = False)\n",
    "    elif fittype =='poly':\n",
    "        print('poly fit, using old K value (do lorentzian fit first)')\n",
    "    print('K sample ' + seldict['sample'] + ' = ' + str(Ks.loc[seldict['sample']]))\n",
    "    \n",
    "    ###Time Series fitting\n",
    "    \n",
    "    vs1 = vss.sel(seldict).dropna('fluence','all').dropna('freq','all').dropna('time','all')\n",
    "    \n",
    "    times = vs1.indexes['time']\n",
    "    timeidx1 = pd.Series(abs(times-time1)).idxmin()\n",
    "    timeidx2 = pd.Series(abs(times-time2)).idxmin()\n",
    "    dt = times[1] - times[0]\n",
    "    idxstep = int(timestep/dt)\n",
    "    \n",
    "    fittimes = times[slice(timeidx1,timeidx2,idxstep)]\n",
    "#     print('fitting for time idxs ' + str(fittimes) )\n",
    "    \n",
    "    i=0\n",
    "    numflus = len(vs1.indexes['fluence'][flus.start:flus.stop:flus.step])\n",
    "    for flu in vs1.indexes['fluence'][flus]:\n",
    "        vs2 = vs1.sel(fluence = flu)\n",
    "        \n",
    "        print(str((i/numflus)*100.0) + ' %') \n",
    "        i=i+1\n",
    "        for time in fittimes:\n",
    "            vs3 = vs2.dropna('freq','all').sel(time = time)\n",
    "            if fittype == 'lor' or fittype == 'lorline':\n",
    "                ##Set minimum frequency to minimum of data\n",
    "                p0[0] = None\n",
    "                p0[2] = Rinfv0 \n",
    "            bounds = defaultbounds(fittype,fixR0, Rinf = Rinfv0)\n",
    "            \n",
    "            #perform fit\n",
    "            vs_fit, vs_p,vs_sl = analysis.fitsweep(vs3, p0, bounds, window , fittype,p_labels)\n",
    "            popt = vs_p[0]\n",
    "            pcov = vs_p[1]\n",
    "            perr = np.sqrt(np.diag(pcov))\n",
    "            \n",
    "            #Fill paramter data sets\n",
    "            \n",
    "            freqs = vs3.indexes['freq'][vs_sl]\n",
    "            seldict_coords = copy.deepcopy(seldict)\n",
    "            seldict_coords['fluence'] = flu\n",
    "            seldict_coords['time'] = time    \n",
    "            \n",
    "            paramlength = 2 if fittype == 'poly' else 4 #polyfit artifically puts f0 and R0 in popt\n",
    "            for i in range(paramlength):\n",
    "                var = list(ds_p_r.data_vars)[i]\n",
    "                ds_p_r[var].loc[seldict_coords] = popt[i]\n",
    "                ds_cov_r[var].loc[seldict_coords] = perr[i]\n",
    "                     \n",
    "            seldict_coords['freq'] = freqs\n",
    "            fits.loc[seldict_coords] = vs_fit(freqs).values   # Note that freqs is also in the index, only updating the freqeuncies that correspond to that sample\n",
    "                    \n",
    "fits.name = 'fits'\n",
    "dvs.name = 'dvs'\n",
    "vss.name = 'vss'\n",
    "            \n",
    "das = [dvs,fits,vss]\n",
    "ds = xr.merge(das)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Fit results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc951f4e3ff449f681548824f326eac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb90f2cdfbe470da244f158fc8d2040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=890.0, description='timesel', max=1790.0, step=10.0), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "mpl.rc('font',**{'size' : 16})\n",
    "\n",
    "samp = v0s.indexes['sample'][0]\n",
    "# samp = 'bic_3'\n",
    "dist = 9\n",
    "\n",
    "### Pull out arrays for one sample and get rid of nas\n",
    "dst = ds.sel(sample = samp,dist = dist).sel(direction = 'U').drop('direction')#.sel(time = times) #try drop any fluence nan...\n",
    "\n",
    "fits_samp = dst['fits'].dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "fittimes = fits_samp.indexes['time']\n",
    "#cut down dvs and fits to only fit times. \n",
    "dvs_samp = dst['dvs'].sel(time = fittimes).dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "vss_samp = dst['vss'].sel(time = fittimes).dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "dst_samp = xr.merge([dvs_samp,fits_samp,vss_samp])\n",
    "\n",
    "\n",
    "\n",
    "### Setup initial plot with items at time =0 eventually should be removed\n",
    "v0 = v0s.sel(sample = samp,dist = dist).sel(direction = 'U').drop('direction').dropna('freq','all')\n",
    "fit_v0 = fits_v0.sel(sample = samp,dist = dist).sel(direction = 'U').drop('direction').dropna('freq','all')\n",
    "dv = dst_samp['dvs'].isel(time = 0 )\n",
    "fit = dst_samp['fits'].isel(time = 0 )\n",
    "vs = dst_samp['vss'].isel(time = 0 )\n",
    "\n",
    "# human readable time array for slider\n",
    "hrtimes = fittimes.values*1e9\n",
    "hrtimetup = (hrtimes[0],hrtimes[-1],hrtimes[1]-hrtimes[0])\n",
    "\n",
    "fig, axes, lns = plot.vsplotxr(dv, vs = vs, fit = fit, v0 = v0, fit_v0 = fit_v0, plotkwargs={'figsize' : (10,8)})\n",
    "\n",
    "buffer = (dvs_samp.max() - dvs_samp.min())/10\n",
    "axes[0].set_ylim([dvs_samp.min()-buffer,dvs_samp.max()+buffer])\n",
    "# axes[0].margins(y = 0.2)\n",
    "axes[1].set_ylim([0,30e-3])\n",
    "\n",
    "interact(plot.inter_vsplot, timesel=hrtimetup   ,dst_samp = fixed(dst_samp),lns = fixed(lns), fig = fixed(fig));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.sweepfitanim(dst, interval = 100)   # Not currently working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_p_r['Rinf'].isel(fluence = -1).sel(direction = 'D').sel(sample = 'bia').dropna('time').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "g = (ds_cov_r['R0']/ds_p_r['R0']).sel(direction = 'U').dropna('fluence','all').plot(hue = 'dist', col = col)\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_ylim([-1,2])\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "    \n",
    "    lns = ax.lines\n",
    "    for ln in lns:\n",
    "        plot.dropna_ln(ln)\n",
    "        \n",
    "fig.suptitle('Normalized Standard Deviation')\n",
    "# fig.tight_layout()\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "if len(fig.legends) > 0:\n",
    "    fig.legends[0].remove()\n",
    "else:\n",
    "    ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the complex conductance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=1\n",
    "\n",
    "ft = ds_p_r['f0']#.sel(direction =direc)\n",
    "f0 = ft.isel(time = 0)\n",
    "sigi = -1*(ft-f0)*e0/F\n",
    "sigiu = -1*(ds_cov_r['f0'])*e0/F\n",
    "\n",
    "# Calculate conductance from FWHM\n",
    "wt = ds_p_r['w']\n",
    "w0 = wt.isel(time = 0)\n",
    "deltaFWHM = wt - w0\n",
    "sigr = deltaFWHM*e0/(2*F)\n",
    "\n",
    "# Calculate real conductance from deltaR/R   \n",
    "# def R02cond(R0t):\n",
    "#     samp = R0t.coords['sample'].values.item()\n",
    "#     K = Ks[samp]\n",
    "#     R0t0 = R0t.dropna('time','all').isel(time = 0)\n",
    "#     cond = ((R0t-R0t0)/R0t0)/K\n",
    "#     return cond\n",
    "\n",
    "# sigr = ds_p_r['R0'].groupby('sample').apply(R02cond)\n",
    "\n",
    "sigr.name = 'real'\n",
    "sigi.name = 'im'\n",
    "\n",
    "sigr.attrs = {'units': 'S', 'long_name': '$\\Delta G_r $'}\n",
    "sigi.attrs = {'units': 'S', 'long_name': '$\\Delta G_i $'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sigr.isel(sample = 0,fluence = 0).plot(x = 'time',hue = 'dist', row = row )\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "#     ax.set_yscale('log')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "#     ax.set_ylim([1e-9,2e-6])\n",
    "    lns = ax.lines\n",
    "    for i, ln in enumerate(lns):\n",
    "        plot.dropna_ln(ln)\n",
    "        color = (0,i/len(lns),i/len(lns))\n",
    "#         ln.set_color(color)\n",
    "    \n",
    "plt.xlim([0,500e-9])\n",
    "fig.suptitle('Real Conductivity')\n",
    "# fig.tight_layout()\n",
    "# fig.legends[0].remove() if len(fig.legends) > 0 else ax.get_legend().remove()\n",
    "fig.tight_layout(rect = [0,0,1,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sigi.isel(sample = 0,fluence = 0).plot(x = 'time',hue = 'dist', row = row )\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "#     ax.set_ylim([1e-9,2e-6])\n",
    "    lns = ax.lines\n",
    "    for i, ln in enumerate(lns):\n",
    "        plot.dropna_ln(ln)\n",
    "        color = (0,i/len(lns),i/len(lns))\n",
    "#         ln.set_color(color)\n",
    "    \n",
    "        \n",
    "fig.suptitle('Real Conductivity')\n",
    "# fig.tight_layout()\n",
    "# fig.legends[0].remove() if len(fig.legends) > 0 else ax.get_legend().remove()\n",
    "fig.tight_layout(rect = [0,0,1,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sigr\n",
    "%store sigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da  = (da_dv/da_bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.isel(sample = 0,fluence = 0,direction = 0).mean('time').plot(hue = 'dist')\n",
    "plt.ylim(-0.01,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertianty calculation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
