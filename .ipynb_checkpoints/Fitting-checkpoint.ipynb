{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import re\n",
    "import os\n",
    "import importlib\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter, FuncFormatter\n",
    "\n",
    "import trmc.kin as kin\n",
    "import trmc.load as load\n",
    "import trmc.analysis as analysis\n",
    "import trmc.plot as plot\n",
    "from trmc.plot import exp_formatter\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 8]\n",
    "mpl.rc('font',**{'size' : 16})\n",
    "\n",
    "e0 = 8.854e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r da_dv\n",
    "%store -r da_bv\n",
    "%store -r da_sw\n",
    "%store -r da_dcs\n",
    "\n",
    "da_dv = da_dv.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Delta V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = None if (len(da_dv.indexes['sample']) == 1)  else 'sample'\n",
    "row = None if (len(da_dv.indexes['direction']) == 1)  else 'direction'\n",
    "timeslice = slice(0e-9,1000e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate the dark cavity sweep to match with the delta v data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dcsi = da_dcs.interp_like(da_dv,method = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now just pull out one freqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -10 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e805436c311>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mda_dcsi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfreqt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mda_dcsi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'freqt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'freqt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda_dcsi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfreqt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'freqt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'freq'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index -10 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "# For partial data sets, cut down the dark cavity sweep, not sure if this is nessecary\n",
    "# fmin = da_dv.indexes['freq'].min()\n",
    "# fmax = da_dv.indexes['freq'].max()\n",
    "# idxmin = abs(da_dcs.indexes['freq'] - fmin).argmin()\n",
    "# idxmax = abs(da_dcs.indexes['freq'] - fmax).argmin() + 1 #???\n",
    "\n",
    "idx = -4\n",
    "das = []\n",
    "for samp in da_dcsi.indexes['sample']:\n",
    "    freqt = da_dcsi.sel(sample = samp).dropna('freqt','all').indexes['freqt'][idx]\n",
    "    das.append(da_dcsi.sel(sample = samp).sel(freqt = freqt).drop('freqt').dropna('freq','all'))\n",
    "    \n",
    "v0s = xr.concat(das, dim = 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = da_bv.indexes['sample']\n",
    "# size = len(samples)\n",
    "# fig, axes = plt.subplots(1,size, figsize = (5*size,4*size) , sharey = True, squeeze=False)\n",
    "\n",
    "# for i, samp in enumerate(samples):\n",
    "#     swp_bv_u = da_bv.sel(sample = samp, direction = 'U').dropna('freq','all')\n",
    "#     axes[0][i].plot(swp_bv_u.indexes['freq'],swp_bv_u,marker = 'o', label = 'Up')\n",
    "#     swp_init = da_sw.sel(sample = samp, tc = '_1_', swtime = 0)\n",
    "#     axes[0][i].plot(swp_init.indexes['freq'],swp_init,marker = 'o',label = 'Initial')\n",
    "#     v0= v0s.sel(sample = samp,direction = 'U').dropna('freq','all')\n",
    "#     axes[0][i].plot(v0.to_series(),marker = 'o',label = 'v0')\n",
    "#     axes[0][i].set_title(samp)\n",
    "#     axes[0][i].legend()\n",
    "#     axes[0][i].set_xlabel('Frequency')\n",
    "#     axes[0][0].set_ylabel('Voltage(V)') \n",
    "\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittype = 'lor'\n",
    "# fittype = 'poly'\n",
    "\n",
    "if fittype == 'lor':\n",
    "    Rinf = 0.02125\n",
    "    f0 = None\n",
    "    p0 =[f0,0.01,Rinf,1e7]\n",
    "    p_labels = ['f0','R0','Rinf','w'] \n",
    "    epsilon = 0.001 #problems with fixing R0 when this gets too smalll??? fit does not respond to bounds on R0 properly...\n",
    "    window = 100\n",
    "    samps = v0s.indexes['sample']\n",
    "    Ks = pd.Series(index = samps) #Define only for lorentzian as poly fits need Ks\n",
    "    fixR0 = True\n",
    "\n",
    "# TODO: need to pass out all covariance only happening for one lor fn\n",
    "    \n",
    "elif fittype == 'poly':\n",
    "    window = 2\n",
    "    p_labels = [ 'f0','R0', 'p0','p1','p2']\n",
    "    bounds = ([-np.inf,-np.inf,-np.inf],[np.inf,np.inf,np.inf])\n",
    "    p0 = [.01,1e-9,1e-18]\n",
    "    \n",
    "\n",
    "time1 = 0e-9\n",
    "time2 = 1800e-9\n",
    "timerange = slice(time1,time2)\n",
    "timestep = 10e-9 #not index and has been moved inside for loop...need to check\n",
    "\n",
    "# direcs = v0s.indexes['direction'].values\n",
    "direcs = ['U']\n",
    "\n",
    "samps = v0s.indexes['sample']\n",
    "# samps = ['bia','bid']\n",
    "flus = slice(-1,0,-1)\n",
    "seldicts = list(analysis.dict_product({'sample' :samps, 'direction':direcs}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data and perform fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Setup dictionaries to input paramters into\n",
    "da_p = da_dv.isel(freq = 0).drop('freq').where(False).copy()\n",
    "da_p0 = da_dcs.isel(freqt = 0).drop('freqt').isel(freq = 0).drop('freq').where(False).copy()\n",
    "\n",
    "da_p_dict = {}\n",
    "da_p0_dict = {}\n",
    "for p in p_labels:\n",
    "    da_p_dict[p] = da_p\n",
    "    da_p0_dict[p] = da_p0\n",
    "    \n",
    "#Not exactly sure why I have to do this copying. Otherwise I think the reference to the original numpy array is kept and assignments get all weird\n",
    "ds_p = xr.Dataset(da_p_dict).copy(deep=True)\n",
    "ds_p0 = xr.Dataset(da_p0_dict).copy(deep=True)\n",
    "\n",
    "ds_p_r  =  ds_p.sel(time = timerange).copy(deep = True).where(False)   #nessecary, subselection is currently not done for ds_p0\n",
    "ds_cov_r  =  ds_p.sel(time = timerange).copy(deep = True).where(False)   #nessecary, subselection is currently not done for ds_p0\n",
    "\n",
    "\n",
    "###Generate Vshift data array\n",
    "dvs = da_dv.sel(time = timerange)\n",
    "vss = v0s + dvs\n",
    "\n",
    "###Create data arrays to put fits into\n",
    "fits_v0 = v0s.copy(deep= True).where(False)\n",
    "fits = dvs.copy(deep = True).where(False)\n",
    "\n",
    "#numer of fits for percent indicator, not working. \n",
    "num = len(seldicts)*(abs(flus.stop - flus.start))\n",
    "### FITTING\n",
    "\n",
    "for seldict in seldicts:\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    ### V0 fitting\n",
    "    v0 = v0s.sel(seldict).dropna('freq','all')\n",
    "    samp = seldict['sample']\n",
    "    direc = seldict['direction']\n",
    "    if fittype == 'lor':\n",
    "        ##Set minimum frequency to minimum of data\n",
    "        p0[0] = None    \n",
    "        p0 =[f0,0.01,Rinf,1e7]\n",
    "        bounds = ([0,0,0, 0],[np.inf,np.inf,np.inf, np.inf])\n",
    "    v0_fit, v0_p,v0_sl = analysis.fitsweep(v0, p0, bounds, window , fittype,p_labels)\n",
    "    popt = v0_p[0]\n",
    "    Rinfv0 = popt[2]\n",
    "    freqs = v0.indexes['freq'][v0_sl]\n",
    "    fits_v0.loc[samp,direc,freqs] = v0_fit(freqs)\n",
    "\n",
    "    for j, p in enumerate(ds_p0.data_vars):\n",
    "        ds_p0[p].loc[samp,direc] = popt[j]\n",
    "    \n",
    "    if fittype == 'lor':\n",
    "        Ks[samp] = analysis.calc_K(f0 = popt[0], R0_norm = popt[1]/popt[2],w = popt[3], printparams = False)\n",
    "    elif fittype =='poly':\n",
    "        print('poly fit, using old K value (do lorentzian fit first)')\n",
    "    print('K sample ' + samp + ' = ' + str(Ks.loc[samp]))\n",
    "    \n",
    "    ###Time Series fitting\n",
    "    \n",
    "    vs1 = vss.sel(seldict).dropna('fluence','all').dropna('freq','all').dropna('time','all')\n",
    "    \n",
    "    times = vs1.indexes['time']\n",
    "    timeidx1 = pd.Series(abs(times-time1)).idxmin()\n",
    "    timeidx2 = pd.Series(abs(times-time2)).idxmin()\n",
    "    dt = times[1] - times[0]\n",
    "    idxstep = int(timestep/dt)\n",
    "    \n",
    "    fittimes = times[slice(timeidx1,timeidx2,idxstep)]\n",
    "#     print('fitting for time idxs ' + str(fittimes) )\n",
    "    \n",
    "    i=0\n",
    "    numflus = len(vs1.indexes['fluence'][flus.start:flus.stop:flus.step])\n",
    "    for flu in vs1.indexes['fluence'][flus]:\n",
    "        vs2 = vs1.sel(fluence = flu)\n",
    "        \n",
    "        print(str((i/numflus)*100.0) + ' %') \n",
    "        i=i+1\n",
    "        for time in fittimes:\n",
    "            vs3 = vs2.dropna('freq','all').sel(time = time)\n",
    "            if fittype == 'lor':\n",
    "                ##Set minimum frequency to minimum of data\n",
    "                p0[0] = None\n",
    "                p0[2] = Rinfv0 \n",
    "#                 p0 =[f0,0.01,Rinfv0,1e7]\n",
    "                if fixR0:\n",
    "                    bounds = ([0,0,Rinfv0 - epsilon,0 ],[np.inf,np.inf,Rinfv0 + epsilon,np.inf ])\n",
    "                else:\n",
    "                    bounds = ([0,0,0, 0],[np.inf,np.inf,np.inf, np.inf])\n",
    "            vs_fit, vs_p,vs_sl = analysis.fitsweep(vs3, p0, bounds, window , fittype,p_labels)\n",
    "            popt = vs_p[0]\n",
    "            pcov = vs_p[1]\n",
    "            perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "            freqs = vs3.indexes['freq'][vs_sl]\n",
    "            fits.loc[samp,direc,freqs,flu,time] = vs_fit(freqs).values   # Note that freqs is also in the index, only updating the freqeuncies that correspond to that sample\n",
    "            \n",
    "            #Fill paramter data sets\n",
    "            \n",
    "            if fittype == 'lor':\n",
    "                ds_p_r['f0'].loc[samp,direc,flu,time] = popt[0]\n",
    "                ds_p_r['R0'].loc[samp,direc,flu,time] = popt[1]\n",
    "                ds_p_r['Rinf'].loc[samp,direc,flu,time] = popt[2]\n",
    "                ds_p_r['w'].loc[samp,direc,flu,time] = popt[3]\n",
    "\n",
    "                ds_cov_r['f0'].loc[samp,direc,flu,time] = perr[0]\n",
    "                ds_cov_r['R0'].loc[samp,direc,flu,time] = perr[1]\n",
    "                ds_cov_r['Rinf'].loc[samp,direc,flu,time] = perr[2]\n",
    "                ds_cov_r['w'].loc[samp,direc,flu,time] = perr[3]\n",
    "            elif fittype == 'poly':\n",
    "                ds_p_r['f0'].loc[samp,direc,flu,time] = popt[1]\n",
    "                ds_p_r['R0'].loc[samp,direc,flu,time] = popt[0]\n",
    "                \n",
    "                ds_cov_r['f0'].loc[samp,direc,flu,time] = perr[1]\n",
    "                ds_cov_r['R0'].loc[samp,direc,flu,time] = perr[0]\n",
    "                    \n",
    "fits.name = 'fits'\n",
    "dvs.name = 'dvs'\n",
    "vss.name = 'vss'\n",
    "            \n",
    "das = [dvs,fits,vss]\n",
    "ds = xr.merge(das)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Fit results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "mpl.rc('font',**{'size' : 16})\n",
    "\n",
    "# samp = v0s.indexes['sample'][0]\n",
    "samp = 'cs'\n",
    "\n",
    "### Pull out arrays for one sample and get rid of nas\n",
    "dst = ds.sel(sample = samp).sel(direction = 'U').drop('direction')#.sel(time = times) #try drop any fluence nan...\n",
    "\n",
    "fits_samp = dst['fits'].dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "fittimes = fits_samp.indexes['time']\n",
    "#cut down dvs and fits to only fit times. \n",
    "dvs_samp = dst['dvs'].sel(time = fittimes).dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "vss_samp = dst['vss'].sel(time = fittimes).dropna('fluence','all').dropna('freq','all').dropna('time','all').isel(fluence = -1)#.isel(time = 0)\n",
    "dst_samp = xr.merge([dvs_samp,fits_samp,vss_samp])\n",
    "\n",
    "\n",
    "### Setup initial plot with items at time =0 eventually should be removed\n",
    "v0 = v0s.sel(sample = samp).sel(direction = 'U').drop('direction').dropna('freq','all')\n",
    "fit_v0 = fits_v0.loc[samp].sel(direction = 'U').drop('direction').dropna('freq','all')\n",
    "dv = dst_samp['dvs'].isel(time = 0 )\n",
    "fit = dst_samp['fits'].isel(time = 0 )\n",
    "vs = dst_samp['vss'].isel(time = 0 )\n",
    "\n",
    "# human readable time array for slider\n",
    "hrtimes = fittimes.values*1e9\n",
    "hrtimetup = (hrtimes[0],hrtimes[-1],hrtimes[1]-hrtimes[0])\n",
    "\n",
    "fig, axes, lns = plot.vsplotxr(dv, vs = vs, fit = None, v0 = v0, fit_v0 = None, plotkwargs={'figsize' : (10,8)})\n",
    "\n",
    "buffer = (dvs_samp.max() - dvs_samp.min())/10\n",
    "axes[0].set_ylim([dvs_samp.min()-buffer,dvs_samp.max()+buffer])\n",
    "# axes[0].margins(y = 0.2)\n",
    "\n",
    "interact(plot.inter_vsplot, timesel=hrtimetup   ,dst_samp = fixed(dst_samp),lns = fixed(lns), fig = fixed(fig));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.sweepfitanim(dst, interval = 100)   # Not currently working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_p_r['Rinf'].isel(fluence = -1).sel(direction = 'D').sel(sample = 'bia').dropna('time').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "g = (ds_cov_r['R0']/ds_p_r['R0']).sel(direction = 'U').dropna('fluence','all').plot(hue = 'fluence', col = col)\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_ylim([-1,2])\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "    \n",
    "    lns = ax.lines\n",
    "    for ln in lns:\n",
    "        plot.dropna_ln(ln)\n",
    "        \n",
    "fig.suptitle('Normalized Standard Deviation')\n",
    "# fig.tight_layout()\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "if len(fig.legends) > 0:\n",
    "    fig.legends[0].remove()\n",
    "else:\n",
    "    ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the complex conductance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=1\n",
    "\n",
    "ft = ds_p_r['f0']#.sel(direction =direc)\n",
    "f0 = ft.isel(time = 0)\n",
    "sigi = -1*(ft-f0)*e0/F\n",
    "sigiu = -1*(ds_cov_r['f0'])*e0/F\n",
    "\n",
    "# Calculate conductance from FWHM\n",
    "# wt = ds_p_r['w']\n",
    "# w0 = wt.isel(time = 0)\n",
    "# deltaFWHM = wt - w0\n",
    "# sigr = deltaFWHM*e0/(2*F)\n",
    "\n",
    "# Calculate real conductance from deltaR/R   \n",
    "def R02cond(R0t):\n",
    "    samp = R0t.coords['sample'].values.item()\n",
    "    K = Ks[samp]\n",
    "    R0t0 = R0t.dropna('time','all').isel(time = 0)\n",
    "    cond = ((R0t-R0t0)/R0t0)/K\n",
    "    return cond\n",
    "\n",
    "sigr = ds_p_r['R0'].groupby('sample').apply(R02cond)\n",
    "\n",
    "# sigr.name = '$\\Delta G_r $ (S)'\n",
    "# sigi.name = '$\\Delta G_i $ (S)'\n",
    "\n",
    "\n",
    "sigr.name = 'real'\n",
    "sigi.name = 'im'\n",
    "\n",
    "sigr.attrs = {'units': 'S', 'long_name': '$\\Delta G_r $'}\n",
    "sigi.attrs = {'units': 'S', 'long_name': '$\\Delta G_i $'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sigr.plot(x = 'time',hue = 'fluence',col = col, row = row )\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "#     ax.set_ylim([1e-9,2e-6])\n",
    "    lns = ax.lines\n",
    "    for i, ln in enumerate(lns):\n",
    "        plot.dropna_ln(ln)\n",
    "        color = (0,i/len(lns),i/len(lns))\n",
    "        ln.set_color(color)\n",
    "    \n",
    "        \n",
    "fig.suptitle('Real Conductivity')\n",
    "# fig.tight_layout()\n",
    "fig.legends[0].remove() if len(fig.legends) > 0 else ax.get_legend().remove()\n",
    "fig.tight_layout(rect = [0,0,1,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = None if (len(da_dv.indexes['sample']) == 1)  else 'sample'\n",
    "row = None if (len(da_dv.indexes['direction']) == 1)  else 'direction'\n",
    "g = sigi.plot(x = 'time',hue = 'fluence',col = col, row = row )\n",
    "\n",
    "axes = g.axes.flatten() if type(g) is xr.plot.facetgrid.FacetGrid else [g[0].axes]\n",
    "fig = g.fig if type(g) is xr.plot.facetgrid.FacetGrid else g[0].figure\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "#     ax.set_ylim([1e-9,2e-4])\n",
    "    lns = ax.lines\n",
    "    for i, ln in enumerate(lns):\n",
    "        plot.dropna_ln(ln)\n",
    "        color = (0,i/len(lns),i/len(lns))\n",
    "        ln.set_color(color)\n",
    "        \n",
    "fig.suptitle('Imaginary Conductivity')\n",
    "# fig.tight_layout()\n",
    "\n",
    "fig.legends[0].remove() if len(fig.legends) > 0 else ax.get_legend().remove()\n",
    "fig.tight_layout(rect = [0,0,1,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sigr\n",
    "%store sigi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertianty calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uncertainties.unumpy as unp\n",
    "\n",
    "# R0u = unp.uarray(ds_p_r['R0'].values,ds_cov_r['R0'].values)\n",
    "# daR0u = xr.DataArray(R0u, coords = ds_p_r['R0'].coords, dims = ds_p_r['R0'].dims)\n",
    "# sigruarr= daR0u.groupby('sample').apply(R02cond)\n",
    "    \n",
    "# sigr = unp.nominal_values(sigruarr.values)\n",
    "# sigru = unp.std_devs(sigruarr.values)\n",
    "# sigr = xr.DataArray(sigr, coords = ds_p_r['R0'].coords, dims = ds_p_r['R0'].dims)\n",
    "# sigru = xr.DataArray(sigru, coords = ds_p_r['R0'].coords, dims = ds_p_r['R0'].dims)\n",
    "\n",
    "# f0u = unp.uarray(ds_p_r['f0'].values,ds_cov_r['f0'].values)\n",
    "\n",
    "# daf0u = xr.DataArray(f0u, coords = ds_p_r['f0'].coords, dims = ds_p_r['f0'].dims)\n",
    "# f0t0 = daf0u.isel(time = 0)\n",
    "# sigiuarr = -1*(daf0u-f0t0)*e0/F\n",
    "    \n",
    "# sigi = unp.nominal_values(sigiuarr.values)\n",
    "# sigiu = unp.std_devs(sigiuarr.values)\n",
    "# sigi = xr.DataArray(sigi, coords = ds_p_r['f0'].coords, dims = ds_p_r['f0'].dims)\n",
    "# sigiu = xr.DataArray(sigiu, coords = ds_p_r['f0'].coords, dims = ds_p_r['f0'].dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (10,4), sharey = False)\n",
    "fluencesel = -1\n",
    "uc = True\n",
    "\n",
    "for sample in sigi.indexes['sample']:\n",
    "    s = sigi.sel(sample = sample).dropna('fluence','all').isel(fluence = fluencesel).sel(direction = 'U').dropna('time','all').to_series()\n",
    "    axes[1].xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "    axes[1].set_xlabel('Time (ns)')\n",
    "    axes[1].plot(s, label = sample)\n",
    "    axes[1].set_title('Imaginary')\n",
    "    axes[1].set_ylabel('$\\Delta G (S)$')\n",
    "\n",
    "    if uc:\n",
    "        su = sigiu.sel(sample = sample).dropna('fluence','all').isel(fluence = fluencesel).sel(direction = 'U').dropna('time','all').to_series()\n",
    "        axes[1].fill_between(s.index, (s-su).values, (s+su).values, alpha = 0.1, color = 'black')\n",
    "    \n",
    "    s = sigr.sel(sample = sample).dropna('fluence','all').isel(fluence = fluencesel).sel(direction = 'U').dropna('time','all').to_series()\n",
    "    axes[0].xaxis.set_major_formatter(FuncFormatter(plot.exp_formatter(-9).func))\n",
    "    axes[0].set_xlabel('Time (ns)')\n",
    "    axes[0].plot(s, label = sample)\n",
    "    axes[0].set_title('Real')\n",
    "    axes[0].set_ylabel('$\\Delta G (S)$')\n",
    "    if uc:\n",
    "        su = sigru.sel(sample = sample).dropna('fluence','all').isel(fluence = fluencesel).sel(direction = 'U').dropna('time','all').to_series()\n",
    "        axes[0].fill_between(s.index, (s-su).values, (s+su).values, alpha = 0.1, color = 'black')\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "fig.suptitle('Fitted $\\Delta$G', y = 1.08)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
